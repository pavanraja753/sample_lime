{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of 1. DIGIT classification with LIME.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4X74lOjm2LCa",
        "colab_type": "text"
      },
      "source": [
        "# Understanding the DIGIT classification on MNIST dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38iwQ9QO4dRf",
        "colab_type": "text"
      },
      "source": [
        "### MNIST data set consists of digits from 0- 9\n",
        "-  Each sample image is 28x28 and linearized as a vector of size 1x784. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfeiPje-2S8h",
        "colab_type": "text"
      },
      "source": [
        "# **Downloading the dependencies- LIME**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LSML3Mr2cpF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "302c5de3-c706-4267-93fb-7ee051ea8c93"
      },
      "source": [
        "#installing lime and other dependencies\n",
        "!pip install lime "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lime in /usr/local/lib/python3.6/dist-packages (0.1.1.36)\n",
            "Requirement already satisfied: scikit-image>=0.12; python_version >= \"3.0\" in /usr/local/lib/python3.6/dist-packages (from lime) (0.15.0)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from lime) (0.21.3)\n",
            "Requirement already satisfied: matplotlib; python_version >= \"3.0\" in /usr/local/lib/python3.6/dist-packages (from lime) (3.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from lime) (1.17.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from lime) (1.3.3)\n",
            "Requirement already satisfied: imageio>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.12; python_version >= \"3.0\"->lime) (2.4.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.12; python_version >= \"3.0\"->lime) (4.3.0)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.12; python_version >= \"3.0\"->lime) (1.1.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.12; python_version >= \"3.0\"->lime) (2.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18->lime) (0.14.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib; python_version >= \"3.0\"->lime) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib; python_version >= \"3.0\"->lime) (2.6.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib; python_version >= \"3.0\"->lime) (2.4.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib; python_version >= \"3.0\"->lime) (0.10.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.3.0->scikit-image>=0.12; python_version >= \"3.0\"->lime) (0.46)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.12; python_version >= \"3.0\"->lime) (4.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib; python_version >= \"3.0\"->lime) (42.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib; python_version >= \"3.0\"->lime) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScTha9yV2aiD",
        "colab_type": "text"
      },
      "source": [
        "# **Importing necessary packages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j97TtZdytsWE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.color import gray2rgb, rgb2gray, label2rgb # since the code wants color images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sK9rR51v2cPZ",
        "colab_type": "text"
      },
      "source": [
        "# **Fetching the dataset and adjusting the images (reshape for lime to function)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amxARb_Mwznh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "mnist = fetch_openml('mnist_784')\n",
        "# make each image color so lime_image works correctly\n",
        "X_vec = np.stack([gray2rgb(iimg) for iimg in mnist.data.reshape((-1, 28, 28))],0)\n",
        "y_vec = mnist.target.astype(np.uint8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlnWySY82t2Q",
        "colab_type": "text"
      },
      "source": [
        "# **Sample Image in dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bzU-TQtw43I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "6c263da0-bb62-4a41-df9c-d813f0380ec1"
      },
      "source": [
        "%matplotlib inline\n",
        "fig, ax1 = plt.subplots(1,1)\n",
        "ax1.imshow(X_vec[2], interpolation = 'none')\n",
        "ax1.set_title('Digit: {}'.format(y_vec[2]))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Digit: 4')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWdo5AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tv3ftAPy0JgE",
        "colab_type": "text"
      },
      "source": [
        "##**Let's Setup a pipeline**\n",
        "\n",
        "**For what?**\n",
        "- For processing the images where we flatten the image back to 1d vectors and then use a RandomForest Classifier.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzfMMf_O2I23",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing necessary libraries\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jXLEcrLxQOM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PipeStep(object):\n",
        "    \"\"\"\n",
        "    Wrapper for turning functions into pipeline transforms (no-fitting)\n",
        "    \"\"\"\n",
        "    def __init__(self, step_func):\n",
        "        self._step_func=step_func\n",
        "    def fit(self,*args):\n",
        "        return self\n",
        "    def transform(self,X):\n",
        "        return self._step_func(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6cvqVHt1-Sq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#converting image to gray\n",
        "makegray_step = PipeStep(lambda img_list: [rgb2gray(img) for img in img_list])\n",
        "\n",
        "#Flatenning the image to 1D array\n",
        "flatten_step = PipeStep(lambda img_list: [img.ravel() for img in img_list])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xst9OdV32AgI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Setting up the main pipeline\n",
        "simple_dt_pipeline = Pipeline([\n",
        "    ('Make Gray', makegray_step),\n",
        "    ('Flatten Image', flatten_step),\n",
        "    #('Normalize', Normalizer()),\n",
        "    #('PCA', PCA(16)),\n",
        "    ('DT', DecisionTreeClassifier(criterion = \"gini\", \n",
        "            random_state = 100,max_depth=7, min_samples_leaf=5) )\n",
        "                              ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMtZUBLS28Ak",
        "colab_type": "text"
      },
      "source": [
        "**Preparing the test train split for the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHhh-6ES2RTH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_vec, y_vec,\n",
        "                                                    train_size=0.55)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMUg-QMp3CGd",
        "colab_type": "text"
      },
      "source": [
        "**Training the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6QpuS6i2UPD",
        "colab_type": "code",
        "outputId": "d9a66993-8864-4af1-9480-60542b603507",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "#training a random forest\n",
        "simple_dt_pipeline.fit(X_train, y_train)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('Make Gray', <__main__.PipeStep object at 0x7f28ceccdb70>),\n",
              "                ('Flatten Image', <__main__.PipeStep object at 0x7f28ceccdc50>),\n",
              "                ('DT',\n",
              "                 DecisionTreeClassifier(class_weight=None, criterion='gini',\n",
              "                                        max_depth=7, max_features=None,\n",
              "                                        max_leaf_nodes=None,\n",
              "                                        min_impurity_decrease=0.0,\n",
              "                                        min_impurity_split=None,\n",
              "                                        min_samples_leaf=5, min_samples_split=2,\n",
              "                                        min_weight_fraction_leaf=0.0,\n",
              "                                        presort=False, random_state=100,\n",
              "                                        splitter='best'))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjvyubrjSImT",
        "colab_type": "text"
      },
      "source": [
        "# Let's see how the decision tree performs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2qlj-bVSNEP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "3d85cc51-09cf-4110-a5a6-34a0b1268f02"
      },
      "source": [
        "y_pred = simple_dt_pipeline.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "\n",
        "print(\"Accuracy: \", accuracy_score(y_test, y_pred)*100 , \"%\")\n",
        "print(\"Confusion Matrix: \\n\",confusion_matrix(y_test, y_pred))\n",
        "print(\"\\n\\n\",classification_report(y_test, y_pred))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  77.80952380952381 %\n",
            "Confusion Matrix: \n",
            " [[2597    3   19   59   62  204   61    3   62   42]\n",
            " [   1 3146  126   53    6   36   17   51   34   52]\n",
            " [  60   67 2450   51  121   59   85   60   75   89]\n",
            " [  41   17  169 2258   52  416   21   44   68  124]\n",
            " [  19   15   53   27 2414  112   58   52   46  325]\n",
            " [  60   56   23  180  102 2075   83   32   82  137]\n",
            " [  61   46  118   19  232  115 2353    8   67   83]\n",
            " [  15   32  174   33   39   44   27 2636   21  262]\n",
            " [  16   75  101  123  102  230   97   31 2102  186]\n",
            " [  31    9   39  114  143  130   27  129   39 2479]]\n",
            "\n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.83      0.86      3112\n",
            "           1       0.91      0.89      0.90      3522\n",
            "           2       0.75      0.79      0.77      3117\n",
            "           3       0.77      0.70      0.74      3210\n",
            "           4       0.74      0.77      0.76      3121\n",
            "           5       0.61      0.73      0.66      2830\n",
            "           6       0.83      0.76      0.79      3102\n",
            "           7       0.87      0.80      0.83      3283\n",
            "           8       0.81      0.69      0.74      3063\n",
            "           9       0.66      0.79      0.72      3140\n",
            "\n",
            "    accuracy                           0.78     31500\n",
            "   macro avg       0.78      0.78      0.78     31500\n",
            "weighted avg       0.79      0.78      0.78     31500\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuiP4w1C2aN1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "import os,sys\n",
        "try:\n",
        "    import lime\n",
        "except:\n",
        "    sys.path.append(os.path.join('..', '..')) # add the current directory\n",
        "    import lime"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tCrCG6L4FSb",
        "colab_type": "text"
      },
      "source": [
        "## Explaining the inference using LIME.\n",
        "Does it explain better than our existing metrics?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQKMaXEX2pWB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from lime import lime_image\n",
        "from lime.wrappers.scikit_image import SegmentationAlgorithm\n",
        "#LimeImageExplainer object explains the inference\n",
        "'''\n",
        "  lime.lime_image.LimeImageExplainer(kernel_width=0.25, verbose=False, feature_selection='auto')\n",
        "  verbose – if true, print local prediction values from linear model\n",
        "'''\n",
        "explainer = lime_image.LimeImageExplainer(verbose = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enuG9c6BzgkH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "first argument: algo_type: string, segmentation algorithm among the following: 'quickshift', 'slic', 'felzenszwalb'\n",
        "quickshift: segmentation using \n",
        "slic: segmentation using k-means\n",
        "felzenszwalb: minimum spanning tree based clustering on the image grid\n",
        "quickshift mode-seeking algorithm\n",
        "\n",
        "kernel_size = Width of Gaussian kernel used in smoothing\n",
        "max_dist: Cut-off point for data distances. Higher means fewer clusters.\n",
        "ratio: range [0,1] Balances color-space proximity and image-space proximity\n",
        "'''\n",
        "segmenter = SegmentationAlgorithm('quickshift', kernel_size=1, max_dist=200, ratio=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c73JqRqm2mA8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "#testidx can be changed to check for different examples\n",
        "testidx = 7\n",
        "'''\n",
        "  An Explanation object (see explanation.py) with the corresponding explanations.\n",
        "'''\n",
        "\n",
        "explanation = explainer.explain_instance(X_test[testidx], \n",
        "                                         classifier_fn = simple_dt_pipeline.predict_proba, \n",
        "                                         top_labels=10, hide_color=0, num_samples=10000, segmentation_fn=segmenter)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gonc96HA2w8d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#marking the positive features\n",
        "'''\n",
        "  num_features: number of superpixels to include in explanation\n",
        "  min_weight: minimum weight of the superpixels to include in explanation\n",
        "\n",
        "  Returns:\n",
        "            (image, mask), where image is a 3d numpy array and mask is a 2d\n",
        "            numpy array that can be used with\n",
        "            skimage.segmentation.mark_boundaries\n",
        "'''\n",
        "\n",
        "temp, mask = explanation.get_image_and_mask(y_test[testidx], positive_only=True, num_features=10, hide_rest=False, min_weight = 0.01)\n",
        "fig, (ax1, ax2) = plt.subplots(1,2, figsize = (8, 4))\n",
        "ax1.imshow(label2rgb(mask,temp, bg_label = 0), interpolation = 'nearest')\n",
        "ax1.set_title('Positive Regions for {}'.format(y_test[testidx]))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EE_CEAd1rdU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#marking the negative features\n",
        "temp, mask = explanation.get_image_and_mask(y_test[testidx], positive_only=False, num_features=10, hide_rest=False, min_weight = 0.01)\n",
        "ax2.imshow(label2rgb(3-mask,temp, bg_label = 0), interpolation = 'nearest')\n",
        "ax2.set_title('Positive/Negative Regions for {}'.format(y_test[testidx]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZTUPjEC3NHV",
        "colab_type": "text"
      },
      "source": [
        "##**Visualisation false positives for class of the select testidx**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-m-xSjE3IZO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# now let's see this for every class\n",
        "idx = 10\n",
        "fig, m_axs = plt.subplots(2,5, figsize = (12,6))\n",
        "for i, c_ax in enumerate(m_axs.flatten()):\n",
        "    temp, mask = explanation.get_image_and_mask(i, positive_only=True, num_features=1000, hide_rest=False, min_weight = 0.01 )\n",
        "    c_ax.imshow(label2rgb(mask,X_test[idx], bg_label = 0), interpolation = 'nearest')\n",
        "    c_ax.set_title('Positive for {}\\nActual {}'.format(i, y_test[idx]))\n",
        "    c_ax.axis('off')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Db_mgQch3sbn",
        "colab_type": "text"
      },
      "source": [
        "##Can we find an explanation for a classification that the algorithm classified incorrectly??"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pj3vn-Ttc6f1",
        "colab_type": "text"
      },
      "source": [
        "# **EXERCISE**\n",
        "Here you can run the below cell, where a random wrong predciton is analysed.\n",
        "- You can change parameters like num_samples, top_labels and see the effect of adding parameter batch_size=10 and change the value of batch size.\n",
        "- You can also change the segmenter by changing Segmentation algorithm here. Choose from these ['quickshift', 'slic', 'felzenszwalb']\n",
        "\n",
        "\n",
        "```\n",
        "SegmentationAlgorithm('quickshift', kernel_size=1, max_dist=200, ratio=0.2)\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgL9ObR23rRR",
        "colab_type": "code",
        "outputId": "24fb1ab7-3e5a-4740-9c7c-635f6d5374e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "pipe_pred_test = simple_dt_pipeline.predict(X_test)\n",
        "\n",
        "#selecting a random \n",
        "wrong_idx = np.random.choice(np.where(pipe_pred_test!=y_test)[0])\n",
        "\n",
        "print('Using #{} where the label was {} and the pipeline predicted {}'.format(wrong_idx, y_test[wrong_idx], pipe_pred_test[wrong_idx]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using #22061 where the label was 3 and the pipeline predicted 9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "my1obLI937HH",
        "colab_type": "code",
        "outputId": "c9014c0d-51c2-4bb9-9c1e-14501c00704c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#time elapsed for prediction\n",
        "\n",
        "%%time\n",
        "segmenter = SegmentationAlgorithm('quickshift', kernel_size=1, max_dist=200, ratio=0.2)\n",
        "explanation = explainer.explain_instance(X_test[wrong_idx], \n",
        "                                         classifier_fn = simple_dt_pipeline.predict_proba, \n",
        "                                         top_labels=10, hide_color=0, num_samples=10000, segmentation_fn=segmenter)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2.04 s, sys: 796 ms, total: 2.84 s\n",
            "Wall time: 2.17 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsarVuGK4Dzq",
        "colab_type": "text"
      },
      "source": [
        "##Comparing predicted vs Actual class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7T3bs4S4AGm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# now show them for each class\n",
        "fig, m_axs = plt.subplots(2,5, figsize = (12,6))\n",
        "for i, c_ax in enumerate(m_axs.flatten()):\n",
        "    temp, mask = explanation.get_image_and_mask(i, positive_only=True, num_features=10, hide_rest=False, min_weight = 0.01 )\n",
        "    c_ax.imshow(label2rgb(mask,temp, bg_label = 0), interpolation = 'nearest')\n",
        "    c_ax.set_title('Positive for {}\\nActual {}'.format(i, y_test[wrong_idx]))\n",
        "    c_ax.axis('off')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aq5N1IdbADAF",
        "colab_type": "text"
      },
      "source": [
        "# Summary and Resources"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgi8sOQ64XHK",
        "colab_type": "text"
      },
      "source": [
        "Here, we have used Random forest to classify the digits\n",
        "- To learn more about how random forest works: https://bit.ly/2r1WxbQ\n",
        "- A description of MNIST dataset: https://en.wikipedia.org/wiki/MNIST_database\n",
        "- Understanding how LIME works on regression try this: https://pythondata.com/local-interpretable-model-agnostic-explanations-lime-python/"
      ]
    }
  ]
}